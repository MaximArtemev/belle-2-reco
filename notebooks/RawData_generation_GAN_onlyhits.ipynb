{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modules.mrartemev_ganlib import gans\n",
    "from modules.mrartemev_ganlib import nn as gans_nn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>ADC_ADC_Sig</th>\n",
       "      <th>ADC_ADC_bg</th>\n",
       "      <th>Board</th>\n",
       "      <th>Nhit</th>\n",
       "      <th>Asic_TDC0</th>\n",
       "      <th>Asic_ADC0</th>\n",
       "      <th>Asic_TOT0</th>\n",
       "      <th>Asic_TDC1</th>\n",
       "      <th>Asic_ADC1</th>\n",
       "      <th>...</th>\n",
       "      <th>Asic_TOT4</th>\n",
       "      <th>Asic_TDC5</th>\n",
       "      <th>Asic_ADC5</th>\n",
       "      <th>Asic_TOT5</th>\n",
       "      <th>Asic_TDC6</th>\n",
       "      <th>Asic_ADC6</th>\n",
       "      <th>Asic_TOT6</th>\n",
       "      <th>Asic_TDC7</th>\n",
       "      <th>Asic_ADC7</th>\n",
       "      <th>Asic_TOT7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.143853</td>\n",
       "      <td>-0.002085</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.10177</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.024574</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.014588</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  ADC_ADC_Sig  ADC_ADC_bg  Board  Nhit  Asic_TDC0  Asic_ADC0  \\\n",
       "0     41.0    -0.001751        -1.0    3.0   1.0       -1.0       -1.0   \n",
       "1     14.0     0.000875        -1.0   15.0   1.0       -1.0       -1.0   \n",
       "2     15.0    -0.003015        -1.0   34.0   1.0       -1.0       -1.0   \n",
       "3     12.0     0.003501        -1.0   35.0   1.0       -1.0       -1.0   \n",
       "4     12.0     0.014588        -1.0   56.0   1.0       -1.0       -1.0   \n",
       "\n",
       "   Asic_TOT0  Asic_TDC1  Asic_ADC1  ...  Asic_TOT4  Asic_TDC5  Asic_ADC5  \\\n",
       "0       -1.0   0.143853  -0.002085  ...  -1.000000       -1.0       -1.0   \n",
       "1       -1.0  -1.000000  -1.000000  ...  -1.000000       -1.0       -1.0   \n",
       "2       -1.0  -1.000000  -1.000000  ...  -1.000000       -1.0       -1.0   \n",
       "3       -1.0  -1.000000  -1.000000  ...   0.047619       -1.0       -1.0   \n",
       "4       -1.0  -1.000000  -1.000000  ...   0.047619       -1.0       -1.0   \n",
       "\n",
       "   Asic_TOT5  Asic_TDC6  Asic_ADC6  Asic_TOT6  Asic_TDC7  Asic_ADC7  Asic_TOT7  \n",
       "0       -1.0   -1.00000  -1.000000       -1.0  -1.000000  -1.000000  -1.000000  \n",
       "1       -1.0    0.10177   0.001617        0.0  -1.000000  -1.000000  -1.000000  \n",
       "2       -1.0   -1.00000  -1.000000       -1.0  -0.024574  -0.004929   0.047619  \n",
       "3       -1.0   -1.00000  -1.000000       -1.0  -1.000000  -1.000000  -1.000000  \n",
       "4       -1.0   -1.00000  -1.000000       -1.0  -1.000000  -1.000000  -1.000000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmic = pd.read_csv('../data/processed/cosmic.csv.gz')\n",
    "cosmic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_NUM)\n",
    "\n",
    "c_cols = ['Channel', 'Board', 'ADC_ADC_Sig']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "For conditional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_disc_cols = ['Channel', 'Board']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channels: [0, 47]\n",
    "\n",
    "Boards: [0, 255]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_context(embeddings, context):\n",
    "    \"\"\"\n",
    "    context: Batch_size x [Channel, Board, ADC_ADC_Sig]\n",
    "    \"\"\"\n",
    "    emb_ind = context[:, 0] + context[:, 1] * 48\n",
    "    context_emb = embeddings(emb_ind.long()).float()\n",
    "    return torch.cat([context_emb, context[:, 2].unsqueeze(1).float()], dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nhit</th>\n",
       "      <th>ADC_ADC_bg</th>\n",
       "      <th>Asic_ADC0</th>\n",
       "      <th>Asic_TDC0</th>\n",
       "      <th>Asic_TOT0</th>\n",
       "      <th>Asic_ADC1</th>\n",
       "      <th>Asic_TDC1</th>\n",
       "      <th>Asic_TOT1</th>\n",
       "      <th>Asic_ADC2</th>\n",
       "      <th>Asic_TDC2</th>\n",
       "      <th>...</th>\n",
       "      <th>Asic_TOT4</th>\n",
       "      <th>Asic_ADC5</th>\n",
       "      <th>Asic_TDC5</th>\n",
       "      <th>Asic_TOT5</th>\n",
       "      <th>Asic_ADC6</th>\n",
       "      <th>Asic_TDC6</th>\n",
       "      <th>Asic_TOT6</th>\n",
       "      <th>Asic_ADC7</th>\n",
       "      <th>Asic_TDC7</th>\n",
       "      <th>Asic_TOT7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.002085</td>\n",
       "      <td>0.143853</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.10177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.024574</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nhit  ADC_ADC_bg  Asic_ADC0  Asic_TDC0  Asic_TOT0  Asic_ADC1  Asic_TDC1  \\\n",
       "0   1.0        -1.0       -1.0       -1.0       -1.0  -0.002085   0.143853   \n",
       "1   1.0        -1.0       -1.0       -1.0       -1.0  -1.000000  -1.000000   \n",
       "2   1.0        -1.0       -1.0       -1.0       -1.0  -1.000000  -1.000000   \n",
       "3   1.0        -1.0       -1.0       -1.0       -1.0  -1.000000  -1.000000   \n",
       "4   1.0        -1.0       -1.0       -1.0       -1.0  -1.000000  -1.000000   \n",
       "\n",
       "   Asic_TOT1  Asic_ADC2  Asic_TDC2  ...  Asic_TOT4  Asic_ADC5  Asic_TDC5  \\\n",
       "0  -0.090909       -1.0       -1.0  ...  -1.000000       -1.0       -1.0   \n",
       "1  -1.000000       -1.0       -1.0  ...  -1.000000       -1.0       -1.0   \n",
       "2  -1.000000       -1.0       -1.0  ...  -1.000000       -1.0       -1.0   \n",
       "3  -1.000000       -1.0       -1.0  ...   0.047619       -1.0       -1.0   \n",
       "4  -1.000000       -1.0       -1.0  ...   0.047619       -1.0       -1.0   \n",
       "\n",
       "   Asic_TOT5  Asic_ADC6  Asic_TDC6  Asic_TOT6  Asic_ADC7  Asic_TDC7  Asic_TOT7  \n",
       "0       -1.0  -1.000000   -1.00000       -1.0  -1.000000  -1.000000  -1.000000  \n",
       "1       -1.0   0.001617    0.10177        0.0  -1.000000  -1.000000  -1.000000  \n",
       "2       -1.0  -1.000000   -1.00000       -1.0  -0.004929  -0.024574   0.047619  \n",
       "3       -1.0  -1.000000   -1.00000       -1.0  -1.000000  -1.000000  -1.000000  \n",
       "4       -1.0  -1.000000   -1.00000       -1.0  -1.000000  -1.000000  -1.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_x_cols = ['Nhit', 'ADC_ADC_bg']\n",
    "group_x_cols = {i: [f'Asic_ADC{i}', f'Asic_TDC{i}', f'Asic_TOT{i}'] for i in range(8)}\n",
    "x_cols = ['Nhit', 'ADC_ADC_bg']\n",
    "for i in range(len(group_x_cols)):\n",
    "    x_cols.extend(group_x_cols[i])\n",
    "\n",
    "cosmic[x_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cosmic['Nhit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data structure:\n",
    "\n",
    "**context**: [Channel, Board, ADC_ADC_Sig]\n",
    "\n",
    "**data**: ['Nhit', 'ADC_ADC_bg', 'Asic_ADC{i}', f'Asic_TDC{i}', f'Asic_TOT{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGenerator(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features=32, depth=4, context=False):\n",
    "        super().__init__()\n",
    "        self.initial_net = gans_nn.MLP(in_features, hidden_features, hidden_features, depth, context)\n",
    "        self.hits_net = gans_nn.MLP(hidden_features, 8, hidden_features, depth, context) # Nhits\n",
    "        self.group_nets = gans_nn.MLP(hidden_features, 3 * len(group_x_cols), hidden_features, depth, context)\n",
    "        self.bg_net = gans_nn.MLP(3*len(group_x_cols), 1, hidden_features, depth, context)\n",
    "        \n",
    "    def forward(self, x, context=None):\n",
    "        initial = self.initial_net(x, context)\n",
    "        hits = torch.sigmoid(self.hits_net(initial, context)).unsqueeze(-1)\n",
    "#         hard_hits = (hits > 0.5).float() # deterministic\n",
    "        hard_hits = torch.bernoulli(hits).float() # stochastic\n",
    "        hard_hits_grad = hits + (hard_hits - hits).detach()\n",
    "        # one - hit, zero - nohit\n",
    "        num_hits = hard_hits_grad.sum(1)\n",
    "        \n",
    "        groups = self.group_nets(initial, context=context).view(initial.size(0), len(group_x_cols), 3)\n",
    "        groups = (1 - hard_hits_grad) * (torch.zeros_like(groups).detach() - 1) + hard_hits_grad * groups\n",
    "        groups = groups.view(groups.size(0), len(group_x_cols) * 3)\n",
    "        \n",
    "        adc_bg = self.bg_net(groups, context=context) # связать с num_hits\n",
    "        #  ['Nhit', 'ADC_ADC_bg', 'Asic_ADC{i}', f'Asic_TDC{i}', f'Asic_TOT{i}']\n",
    "        generated = torch.cat([num_hits, adc_bg, groups], dim=1)\n",
    "        return generated\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(x_cols)\n",
    "context_dim = 64\n",
    "\n",
    "\n",
    "prior = torch.distributions.MultivariateNormal(torch.zeros(64).to(device),\n",
    "                                               torch.eye(64).to(device))\n",
    "\n",
    "model = gans.LSGAN(dim, prior, base_network=gans_nn.MLP,\n",
    "                   hidden_features=64, depth=2, context=context_dim\n",
    "                  )\n",
    "model.c_embs = nn.Embedding(256*48, 63)\n",
    "model.c_embs.weight.requires_grad = True\n",
    "model.generator = CustomGenerator(prior.event_shape[0], dim, hidden_features=128, depth=5, context=context_dim)\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "\n",
    "gen_optimizer = torch.optim.Adam([{'params': model.generator.parameters(), 'lr': 1e-4, 'weight_decay': 0.0005},\n",
    "                                  {'params': model.c_embs.parameters(), 'lr': 1e-5}])\n",
    "disc_optimizer = torch.optim.Adam(model.discriminator.parameters(), lr=1e-6)\n",
    "\n",
    "gen_scheduler = torch.optim.lr_scheduler.ExponentialLR(gen_optimizer, 0.99)\n",
    "disc_scheduler = torch.optim.lr_scheduler.ExponentialLR(disc_optimizer, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# context: Channel, Board, ADC_ADC_Sig\n",
    "# data: 'Nhit', 'ADC_ADC_bg', ['Asic_ADC{i}', f'Asic_TDC{i}', f'Asic_TOT{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def get_infinite_loader(loader):\n",
    "    iter_loader = iter(loader)\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(iter_loader)\n",
    "        except StopIteration:\n",
    "            iter_loader = iter(loader)\n",
    "            yield next(iter_loader)\n",
    "            \n",
    "# balance dataset\n",
    "sample_num = 100000\n",
    "balanced_cosmic = cosmic[cosmic['Nhit'] != 1]\n",
    "\n",
    "# balanced_cosmic = pd.concat([cosmic[cosmic['Nhit'] != 1].sample(sample_num), \n",
    "#                              cosmic[cosmic['Nhit'] == 1].sample(sample_num)], axis=0)\n",
    "\n",
    "\n",
    "            \n",
    "train_dataloader = TensorDataset(torch.tensor(balanced_cosmic[x_cols].values),\n",
    "                                 torch.tensor(balanced_cosmic[c_cols].values))\n",
    "train_dataloader = DataLoader(train_dataloader, batch_size=128, shuffle=True, drop_last=True)\n",
    "train_dataloader = get_infinite_loader(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.604836106300354, 1.8196141719818115)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(train_dataloader)\n",
    "x, context = [i.to(device).float() for i in batch]\n",
    "context = encode_context(model.c_embs, context)\n",
    "gen_loss = model.calculate_loss_gen(x, context=context)\n",
    "disc_loss = model.calculate_loss_disc(x, context=context)\n",
    "gen_loss.mean().item(), disc_loss.mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/maximartemev/richgans/ee38ca4a54d64b9989020b8d2473f92d\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     disc/lr [7]            : (9.414801494010001e-07, 1e-06)\n",
      "COMET INFO:     gen/lr [7]             : (9.414801494010001e-05, 0.0001)\n",
      "COMET INFO:     loss [3882]            : (0.0003460478037595749, 3.688354969024658)\n",
      "COMET INFO:     train/disc/loss [9720] : (1.9080756902694702, 3.780816078186035)\n",
      "COMET INFO:     train/gen/loss [9720]  : (0.0002489592880010605, 4.29982852935791)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:   Uploads [count]:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     figures [14]             : 14\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (8 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: old comet version (3.1.4) detected. current: 3.1.6 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET WARNING: Failing to collect the installed os packages\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/maximartemev/richgans/0f644ccd313d436c89760f45226f43f6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(api_key=\"HIZapbzNjFips0c32Co7gXkQZ\",\n",
    "                        project_name=\"richgans\", workspace=\"maximartemev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_INTERVALS = 1500\n",
    "GEN_UPDATES = 3\n",
    "DISC_UPDATES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hits(data):\n",
    "    x_val = cosmic.sample(100000)[x_cols].values\n",
    "    c_val = mc_noct.sample(100000)[c_cols].values\n",
    "    x_gen = model.generate(100000,\n",
    "                           encode_context(model.c_embs,\n",
    "                                          torch.tensor(c_val, device=device)\n",
    "                                         )\n",
    "                          ).detach().cpu().numpy()\n",
    "    plt.figure(figsize=(20, 50))\n",
    "    plot_ind = 0\n",
    "    for ind, col in enumerate(x_cols):\n",
    "        if 'ADC' in col and not 'bg' in col:\n",
    "            plot_ind += 1\n",
    "            plt.subplot(10, 2, plot_ind)\n",
    "            _, bins, _ = plt.hist(x_val[x_val[:, ind] != -1, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "            plt.hist(x_gen[x_gen[:, ind] != -1, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt.title(col)\n",
    "            plot_ind += 1\n",
    "            plt.subplot(10, 2, plot_ind)\n",
    "            _, bins, _ = plt.hist(x_val[x_val[:, ind] == -1, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "            plt.hist(x_gen[x_gen[:, ind] == -1, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt.title(col)\n",
    "        if 'Nhit' in col:\n",
    "            plot_ind += 1\n",
    "            plt.subplot(10, 2, plot_ind)\n",
    "            _, bins, _ = plt.hist(x_val[x_val[:, ind] != 1, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "            plt.hist(x_gen[x_gen[:, ind] != 1, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt.title(col)\n",
    "            plot_ind += 1\n",
    "            plt.subplot(10, 2, plot_ind)\n",
    "            _, bins, _ = plt.hist(x_val[x_val[:, ind] == 1, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "            plt.hist(x_gen[x_gen[:, ind] == 1, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt.title(col)\n",
    "\n",
    "        if 'bg' in col:\n",
    "            plot_ind += 1\n",
    "            plt.subplot(10, 2, plot_ind)\n",
    "            _, bins, _ = plt.hist(x_val[x_val[:, ind] != -1, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "            plt.hist(x_gen[x_gen[:, ind] != -1, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt.title(col)\n",
    "            plot_ind += 1\n",
    "            plt.subplot(10, 2, plot_ind)\n",
    "            _, bins, _ = plt.hist(x_val[x_val[:, ind] == -1, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "            plt.hist(x_gen[x_gen[:, ind] == -1, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt.title(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(data):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    x_val = data[x_cols].values\n",
    "    c_val = data[c_cols].values\n",
    "    x_gen = model.generate(data.shape[0],\n",
    "                           encode_context(model.c_embs,\n",
    "                                          torch.tensor(c_val, device=device)\n",
    "                                         )\n",
    "                          ).detach().cpu().numpy()\n",
    "    \n",
    "    plot_ind = 0\n",
    "    for ind, col in enumerate(x_cols):\n",
    "        if 'ADC' in col or col == 'Nhit':\n",
    "            plot_ind += 1\n",
    "            plt.subplot(5, 2, plot_ind)\n",
    "            _, bins, _ = plt.hist(x_val[:, ind], bins=50, alpha=0.6, label='Real', density=True)\n",
    "            plt.hist(x_gen[:, ind], bins=bins, alpha=0.6, label='Generated', density=True)\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt.title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_noct = pd.read_csv('../data/processed/mcmc_noxtalk.csv.gz', nrows=100000)\n",
    "mc_ct = pd.read_csv('../data/processed/mcmc_xtalk.csv.gz', nrows=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14999/1000000 [23:48<20:19:51, 13.46it/s] /home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  if __name__ == '__main__':\n",
      " 45%|████▍     | 447743/1000000 [13:31:40<16:40:13,  9.20it/s] "
     ]
    }
   ],
   "source": [
    "for iteration in tqdm(range(1000000), position=0, leave=True):\n",
    "    \n",
    "    if iteration % VAL_INTERVALS == 0:\n",
    "        model.eval()\n",
    "        experiment.log_metrics({'gen/lr': gen_optimizer.param_groups[0]['lr'],\n",
    "                                'disc/lr': disc_optimizer.param_groups[0]['lr']},\n",
    "                               step=iteration)\n",
    "\n",
    "        gen_scheduler.step()\n",
    "        disc_scheduler.step()\n",
    "        \n",
    "        plot_hits(mc_noct)\n",
    "        experiment.log_figure('no_ct', step=iteration)\n",
    "        plot_hits(mc_ct)\n",
    "        experiment.log_figure('yes_ct', step=iteration)\n",
    "        plt.clf()\n",
    "    \n",
    "    model.train()\n",
    "    # gen update\n",
    "    for _ in range(GEN_UPDATES):\n",
    "        x, context = [i.to(device).float() for i in next(train_dataloader)]\n",
    "        context = encode_context(model.c_embs, context)\n",
    "        gen_optimizer.zero_grad()\n",
    "        gen_loss = model.calculate_loss_gen(x, context=context).mean()\n",
    "        gen_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        gen_optimizer.step()\n",
    "    experiment.log_metric('train/gen/loss', gen_loss.item(), step=iteration)\n",
    "\n",
    "    # disc update\n",
    "    for _ in range(DISC_UPDATES):\n",
    "        x, context = [i.to(device).float() for i in next(train_dataloader)]\n",
    "        context = encode_context(model.c_embs, context)\n",
    "        disc_optimizer.zero_grad()\n",
    "        disc_loss = model.calculate_loss_disc(x, context=context).mean()\n",
    "        disc_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        disc_optimizer.step()\n",
    "    experiment.log_metric('train/disc/loss', disc_loss.item(), step=iteration)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = cosmic.loc[:100000, x_cols].values\n",
    "c_val = mc_noct.loc[:100000, c_cols].values\n",
    "x_gen = model.generate(100000,\n",
    "                       encode_context(model.c_embs,\n",
    "                                      torch.tensor(c_val, device=device)\n",
    "                                     )\n",
    "                      ).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 50))\n",
    "\n",
    "plot_ind = 0\n",
    "for ind, col in enumerate(x_cols):\n",
    "    if 'ADC' in col and not 'bg' in col:\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] != -1, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] != -1, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] == -1, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] == -1, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "    if 'Nhit' in col:\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] != 1, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] != 1, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] == 1, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] == 1, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "        \n",
    "    if 'bg' in col:\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] != -1, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] != -1, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] == -1, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] == -1, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = mc_noct[x_cols].values\n",
    "c_val = mc_noct[c_cols].values\n",
    "x_gen = model.generate(mc_noct.shape[0],\n",
    "                       encode_context(model.c_embs,\n",
    "                                      torch.tensor(c_val, device=device)\n",
    "                                     )\n",
    "                      ).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 50))\n",
    "\n",
    "plot_ind = 0\n",
    "for ind, col in enumerate(x_cols):\n",
    "    if 'ADC' in col and not 'bg' in col:\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] != -1, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] != -1, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] == -1, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] == -1, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "    if 'Nhit' in col:\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] != 1, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] != 1, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] == 1, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] == 1, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "        \n",
    "    if 'bg' in col:\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] != 0, ind], bins=50, alpha=0.6, label='Real, hits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] != 0, ind], bins=bins, alpha=0.6, label='Generated, hits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "        plot_ind += 1\n",
    "        plt.subplot(10, 2, plot_ind)\n",
    "        _, bins, _ = plt.hist(x_val[x_val[:, ind] == 0, ind], bins=50, alpha=0.6, label='Real, nohits')\n",
    "        plt.hist(x_gen[x_gen[:, ind] == 0, ind], bins=bins, alpha=0.6, label='Generated, nohits')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = mc_ct[x_cols].values\n",
    "c_val = mc_ct[c_cols].values\n",
    "x_gen = model.generate(mc_ct.shape[0],\n",
    "                       encode_context(model.c_embs,\n",
    "                                      torch.tensor(c_val, device=device)\n",
    "                                     )\n",
    "                      ).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "plot_ind = 0\n",
    "for ind, col in enumerate(x_cols):\n",
    "    if 'ADC' in col and not 'bg' in col:\n",
    "        plot_ind += 1\n",
    "        plt.subplot(5, 2, plot_ind)\n",
    "        plt.hist(x_val[:, ind], bins=50, alpha=0.6, label='Real', density=True)\n",
    "        plt.hist(x_gen[:, ind], bins=50, alpha=0.6, label='Generated', density=True)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "plot_ind = 0\n",
    "for ind, col in enumerate(x_cols):\n",
    "    if 'ADC' in col or col == 'Nhit':\n",
    "        plot_ind += 1\n",
    "        plt.subplot(5, 2, plot_ind)\n",
    "        plt.hist(x_val[:, ind], bins=50, alpha=0.6, label='Real', density=True)\n",
    "        plt.hist(x_gen[:, ind], bins=50, alpha=0.6, label='Generated', density=True)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join('../saved_models/', 'first_wgan' + '.state_dict'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_noct = pd.read_csv('../data/raw/mcmc_noxtalk.csv.gz', nrows=100000)\n",
    "plot_compare(mc_noct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_ct = pd.read_csv('../data/raw/mcmc_xtalk.csv.gz', nrows=100000)\n",
    "plot_compare(mc_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
